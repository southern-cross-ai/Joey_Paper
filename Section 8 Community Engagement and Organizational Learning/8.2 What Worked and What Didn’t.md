# 8.2 What Worked and What Didn’t

The open model allowed for fast iteration in some areas, especially during the early stages of dataset collection, exploratory training, and tooling validation. Students and volunteers were able to jump in, contribute to preprocessing, test tokenizers, clean datasets, and explore prompt engineering methods. These loosely coordinated sprints generated meaningful progress particularly during BabyJoey’s development and the curation of initial corpora.

However, coordination wasn’t always smooth. As the project’s scope expanded from fine-tuning to foundational modeling the complexity outpaced the informal structure. Some contributors were more interested in use-case development or deployment; others focused solely on technical research. Expectations diverged, and without clear planning rituals or roadmap alignment, some efforts ran in parallel without integration. The lack of centralized decision-making occasionally slowed progress or duplicated work.

There were also drops in momentum, particularly when contributors became unclear about how or where to contribute. Without defined scopes, role rotation, or structured onboarding, newer participants sometimes felt unsure about how to participate meaningfully.
