# 11. Conclusion

The past year has shown us that building a foundational model is not just a technical task it is a national capability exercise. While fine-tuning can localize outputs, only foundational model development gives the level of control needed to align architecture, data, deployment, and governance with local values and needs. JoeyLLM was born from that realization.

Though our model is still maturing, the process of building BabyJoey and now JoeyLLM has already delivered immense value. It has helped us understand the infrastructure required to train models on Australian data. It has revealed the social complexity of coordinating a civic AI initiative. And it has proven that open, community-driven model development is possible even without the resources of a major AI lab.

We do not claim to have solved all the problems of alignment, scaling, or deployment. But we have made a start one that is grounded in transparency, driven by public interest, and anchored in Australian priorities. What JoeyLLM offers is not just a tool for language generation, but a template for how nations can build their own AI infrastructure from scratch and in the open.
As we continue to grow the project, we extend an invitation not for passive use, but for collaboration. Whether you're in government, academia, research, or the open-source community, the future of sovereign AI will be shaped not by any single model, but by the partnerships we forge around it.

JoeyLLM is our contribution to that future. A model of what can be built together, and on our own terms.

Acknowledgements
The JoeyLLM initiative was made possible through the collaborative efforts of the Southern Cross AI community. We gratefully acknowledge the contributions of student researchers, volunteers, and open-source developers who helped with dataset collection, preprocessing, model experimentation, and governance discussions.

Special thanks to collaborators at the Australian National University (ANU) for early academic engagement, as well as to independent AI practitioners who contributed infrastructure advice, training insights, and feedback throughout the projectâ€™s evolution. We also appreciate the support of contributors who offered compute resources, participated in red-teaming, and engaged in community discussions on Discord and GitHub.

We would also like to acknowledge the foundational work of Colin Choat, founder and curator of Project Gutenberg Australia, whose dedication to preserving and sharing Australian literary heritage provided an essential building block for our early dataset development.

Finally, we thank the broader open-source AI ecosystem including the developers of PyTorch, Hugging Face, DeepSpeed, and tokenization libraries for creating the tools that made this project possible. JoeyLLM would not exist without the collective intelligence of the global machine learning community.

# References



