# 6.2 Platform and Infrastructure Realities

Southern Cross AI is an open-source initiative, not a billion-dollar lab. That means we operate with the constraints of shared infrastructure, academic compute quotas, donated GPU time, and locally available hardware. This shaped every architectural and training decision.
Our environment is primarily Linux-based, with experiments run across a mix of local servers, university research clusters, and limited cloud credits. Many contributors train or fine-tune models on consumer-grade hardware including older NVIDIA cards, laptops, or even CPU-only rigs for preprocessing and evaluation.
These limitations forced us to become efficient early. We adopted lightweight monitoring tools, built modular training loops, and worked to keep our data pipelines GPU-aware and fail-safe. Every optimization had to be justified; every gigabyte mattered. It also meant that decisions made now would have lasting consequences on whether JoeyLLM could actually be used across the country in varied, resource-constrained environments.
