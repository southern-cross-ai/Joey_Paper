# 10.3 Infrastructure and Deployment Research

Scaling a model is only part of the challenge; running and serving it in the real world is equally important. JoeyLLM is being designed with a strong emphasis on offline and edge readiness, particularly for public sector and regional deployment.

Current efforts focus on:

* Dockerized inference environments for use in schools, clinics, and legal services

* Quantized versions of the model for use on CPU-only or older GPU hardware

* Compatibility with academic clusters and pooled community GPU resources

* Secure, reproducible pipelines for training and inference in air-gapped environments

These constraints are not limitations so much as they are design parameters that reflect the environments where sovereignty matters most.
