# 5.1 Realizing the Limitations of Fine-Tuning

Our original plan to fine-tune existing open-weight models using Australian-specific data was grounded in practicality. Fine-tuning seemed more accessible, affordable, and immediately useful. But after early experiments with Mistral-7B and evaluation of community efforts built on LLaMA and similar models, we encountered a consistent pattern: fine-tuning could localize style, but not shift underlying assumptions or limitations.

Models trained elsewhere came with invisible baggage tokenization choices, training data biases, and architectural tradeoffs baked in by external priorities. Even when we applied high-quality, well-structured Australian data, the resulting models retained artifacts of their origin: foreign political assumptions, misaligned tone, incorrect nomenclature and a lack of context for local institutions or norms. It became clear that you can’t align a model to your values if you don’t control how it was built.
