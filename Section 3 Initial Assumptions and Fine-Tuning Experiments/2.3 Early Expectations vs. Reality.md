## 2.3 Early Expectations vs. Reality

The early expectation was that this combination of high-volume, culturally specific data and instruction tuning would produce a sufficiently aligned model with relatively little architectural intervention. In other words, we thought the model would “sound Australian” if trained on Australian content.
Early Observations from Fine-Tuning
As we began evaluating outputs from our fine-tuned Mistral models, it became clear that our initial assumptions were incomplete. The models exhibited issues with coherence, tone drift, and generalization.
Although the fine-tunes produced technically fluent outputs, the models often reverted to stylistic patterns shaped by their original training data. This commonly manifested as caricatured Australian personas—reminiscent of a stereotypical “Crocodile Dundee” figure. The tone leaned exaggerated and boastful, echoing American cultural tropes, and missed the self-deprecating nuance characteristic of Australian communication.
This highlighted a deeper challenge: capturing the subtle cultural cues and linguistic intricacies of Australian English. While the models could mimic local slang or phrasing, they failed to authentically reflect the broader cultural context—underscoring the limits of fine-tuning alone for achieving cultural fidelity.
Even when outputs were factually grounded, they lacked the flexibility, nuance, and relevance required for real-world deployment. Most importantly, we found that cultural alignment could not be achieved through data alone. Architecture, training dynamics, and tokenization strategy played a more decisive role than we had initially anticipated.
This realization prompted a strategic pivot—from adapting existing models to building our own. While not all contributors agreed on this shift, the divergence in viewpoints reflected strong engagement: people cared not just about the technology, but about the direction the project should take.
