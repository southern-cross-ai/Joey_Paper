# 4.2 Model Behavior and Limitations

As expected for a 64M parameter model, BabyJoey struggled to produce coherent or consistent outputs. While it successfully generated grammatically correct phrases and occasional factoids, it often rambled, repeated itself, or lost track of context after just a few lines.
Most notably, the model took on a distinctly old-fashioned tone more like a character from a 1960s bush novel than a contemporary assistant. This was unsurprising: its training data skewed heavily toward older, copyright-free literature, which shaped its vocabulary and style. It often responded in poetic or narrative form, even when prompted with factual or instructional questions.
While charming in tone, it clearly lacked the capacity for real-world use. There were no meaningful reasoning capabilities, and the model failed at even simple question answering tasks outside its narrow training window.